#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube Shorts ë°ì´í„° ìˆ˜ì§‘ê¸° v2 - ë°°ì¹˜ ì²˜ë¦¬ ë²„ì „
ì‚¬ìš©ë²•: ì´ íŒŒì¼ì„ ì‹¤í–‰í•˜ê³  ì•ˆë‚´ì— ë”°ë¼ ì§„í–‰í•˜ì„¸ìš”.

ìƒˆë¡œìš´ ê¸°ëŠ¥:
- CSV íŒŒì¼ì—ì„œ URL ë°°ì¹˜ ì²˜ë¦¬
- í‚¤ì›Œë“œ íƒœê¹…
- ì¸ë„¤ì¼ ìë™ ë‹¤ìš´ë¡œë“œ
- ìë§‰ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
- ì§„í–‰ ìƒí™© ì €ì¥/ì¬ê°œ
- Rate Limiting
- ì¤‘ë³µ ì œê±°
"""

import re
import pandas as pd
from datetime import datetime
import json
import os
import time
import logging
from pathlib import Path
import requests

try:
    from googleapiclient.discovery import build
    print("âœ… Google API ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError:
    print("âŒ Google API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”: pip install google-api-python-client")
    input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    exit()

try:
    from youtube_transcript_api import YouTubeTranscriptApi
    print("âœ… YouTube Transcript API ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError:
    print("âŒ YouTube Transcript API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”: pip install youtube-transcript-api")
    input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    exit()


class YouTubeShortsCollectorV2:
    def __init__(self):
        self.api_key = None
        self.youtube = None
        self.results = []
        self.processed_ids = set()
        self.failed_urls = []
        self.progress_file = "progress.json"
        self.api_key_file = "api_key.txt"
        self.thumbnail_dir = "thumbnails"
        self.setup_logging()
        self.api_call_delay = 0.5  # Rate limiting: 0.5ì´ˆ ëŒ€ê¸°

    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            filename='youtube_collector.log',
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            encoding='utf-8'
        )
        self.logger = logging.getLogger(__name__)

    def load_api_key(self):
        """ì €ì¥ëœ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°"""
        if os.path.exists(self.api_key_file):
            try:
                with open(self.api_key_file, 'r', encoding='utf-8') as f:
                    return f.read().strip()
            except Exception as e:
                self.logger.error(f"API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None

    def save_api_key(self, api_key):
        """API í‚¤ ì €ì¥"""
        try:
            with open(self.api_key_file, 'w', encoding='utf-8') as f:
                f.write(api_key)
            self.logger.info("API í‚¤ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"API í‚¤ ì €ì¥ ì‹¤íŒ¨: {e}")

    def setup_api_key(self):
        """API í‚¤ ì„¤ì •"""
        print("\n" + "="*60)
        print("ğŸ”‘ YouTube Data API í‚¤ ì„¤ì •")
        print("="*60)

        # ì €ì¥ëœ API í‚¤ í™•ì¸
        saved_key = self.load_api_key()
        if saved_key:
            print(f"\nğŸ’¾ ì €ì¥ëœ API í‚¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: {saved_key[:10]}...")
            use_saved = input("ì €ì¥ëœ í‚¤ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()

            if use_saved == 'y':
                try:
                    # API í‚¤ í…ŒìŠ¤íŠ¸
                    youtube = build('youtube', 'v3', developerKey=saved_key)
                    test_response = youtube.videos().list(
                        part='snippet',
                        id='dQw4w9WgXcQ'
                    ).execute()

                    self.api_key = saved_key
                    self.youtube = youtube
                    print("âœ… ì €ì¥ëœ API í‚¤ë¡œ ì„¤ì • ì™„ë£Œ!")
                    self.logger.info("ì €ì¥ëœ API í‚¤ ì‚¬ìš©")
                    return
                except Exception as e:
                    print(f"âŒ ì €ì¥ëœ API í‚¤ ì˜¤ë¥˜: {e}")
                    print("ğŸ’¡ ìƒˆë¡œìš´ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # ìƒˆ API í‚¤ ì…ë ¥
        while True:
            api_key = input("\nğŸ“‹ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

            if not api_key:
                print("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue

            if not api_key.startswith('AIza'):
                print("âŒ ì˜¬ë°”ë¥´ì§€ ì•Šì€ API í‚¤ í˜•ì‹ì…ë‹ˆë‹¤.")
                print("ğŸ’¡ API í‚¤ëŠ” 'AIza'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
                continue

            try:
                # API í‚¤ í…ŒìŠ¤íŠ¸
                youtube = build('youtube', 'v3', developerKey=api_key)
                test_response = youtube.videos().list(
                    part='snippet',
                    id='dQw4w9WgXcQ'
                ).execute()

                self.api_key = api_key
                self.youtube = youtube

                # API í‚¤ ì €ì¥ ì—¬ë¶€ í™•ì¸
                save_choice = input("\nğŸ’¾ ì´ API í‚¤ë¥¼ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                if save_choice == 'y':
                    self.save_api_key(api_key)
                    print("âœ… API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    print("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! (ì €ì¥í•˜ì§€ ì•ŠìŒ)")

                self.logger.info("API í‚¤ ì„¤ì • ì™„ë£Œ")
                break

            except Exception as e:
                print(f"âŒ API í‚¤ ì˜¤ë¥˜: {e}")
                print("ğŸ’¡ API í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                self.logger.error(f"API í‚¤ ì˜¤ë¥˜: {e}")
                continue

    def load_progress(self):
        """ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸°"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.results = data.get('results', [])
                    self.processed_ids = set(data.get('processed_ids', []))
                    self.failed_urls = data.get('failed_urls', [])
                print(f"ğŸ“‚ ì´ì „ ì§„í–‰ ìƒí™©ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ìˆ˜ì§‘ëœ ì˜ìƒ: {len(self.results)}ê°œ)")
                self.logger.info(f"ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {len(self.results)}ê°œ")
                return True
            except Exception as e:
                print(f"âš ï¸ ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                self.logger.error(f"ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return False

    def save_progress(self):
        """ì§„í–‰ ìƒí™© ì €ì¥"""
        try:
            data = {
                'results': self.results,
                'processed_ids': list(self.processed_ids),
                'failed_urls': self.failed_urls,
                'last_updated': datetime.now().isoformat()
            }
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            self.logger.info(f"ì§„í–‰ ìƒí™© ì €ì¥ ì™„ë£Œ: {len(self.results)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {e}")
            self.logger.error(f"ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {e}")

    def extract_video_id(self, url):
        """YouTube URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ"""
        patterns = [
            r'(?:youtube\.com/shorts/)([^&\n?#]+)',
            r'(?:youtube\.com/watch\?v=)([^&\n?#]+)',
            r'(?:youtu\.be/)([^&\n?#]+)'
        ]

        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        return None

    def download_thumbnail(self, video_id, thumbnail_url):
        """ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            # ì¸ë„¤ì¼ ë””ë ‰í† ë¦¬ ìƒì„±
            Path(self.thumbnail_dir).mkdir(exist_ok=True)

            # íŒŒì¼ëª… ìƒì„±
            filename = f"{video_id}.jpg"
            filepath = os.path.join(self.thumbnail_dir, filename)

            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²½ìš° ê±´ë„ˆë›°ê¸°
            if os.path.exists(filepath):
                return filename

            # ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ
            response = requests.get(thumbnail_url, timeout=10)
            if response.status_code == 200:
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                return filename
            else:
                self.logger.warning(f"ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {video_id}")
                return None

        except Exception as e:
            self.logger.error(f"ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ ({video_id}): {e}")
            return None

    def get_transcript(self, video_id):
        """ìë§‰ ì¶”ì¶œ"""
        try:
            # í•œêµ­ì–´ ìë§‰ ìš°ì„ , ì—†ìœ¼ë©´ ìë™ìƒì„± ìë§‰, ê·¸ê²ƒë„ ì—†ìœ¼ë©´ ì˜ì–´
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)

            try:
                # í•œêµ­ì–´ ìë§‰ ì‹œë„
                transcript = transcript_list.find_transcript(['ko'])
            except:
                try:
                    # ìë™ìƒì„± í•œêµ­ì–´ ìë§‰ ì‹œë„
                    transcript = transcript_list.find_generated_transcript(['ko'])
                except:
                    try:
                        # ì˜ì–´ ìë§‰ ì‹œë„
                        transcript = transcript_list.find_transcript(['en'])
                    except:
                        return None

            # ìë§‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            transcript_data = transcript.fetch()
            full_text = ' '.join([entry['text'] for entry in transcript_data])
            return full_text

        except Exception as e:
            self.logger.info(f"ìë§‰ ì—†ìŒ ({video_id}): {str(e)}")
            return None

    def get_video_info(self, video_id, keyword=None):
        """ë¹„ë””ì˜¤ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # Rate Limiting
            time.sleep(self.api_call_delay)

            # ë¹„ë””ì˜¤ ê¸°ë³¸ ì •ë³´
            video_response = self.youtube.videos().list(
                part='snippet,statistics,contentDetails',
                id=video_id
            ).execute()

            if not video_response['items']:
                return None

            video = video_response['items'][0]
            snippet = video['snippet']
            statistics = video['statistics']

            # ì¸ë„¤ì¼ URL ë° ë‹¤ìš´ë¡œë“œ
            thumbnails = snippet.get('thumbnails', {})
            thumbnail_url = thumbnails.get('medium', {}).get('url', '')
            thumbnail_filename = self.download_thumbnail(video_id, thumbnail_url) if thumbnail_url else None

            # ìë§‰ ì¶”ì¶œ
            transcript = self.get_transcript(video_id)

            # Rate Limiting
            time.sleep(self.api_call_delay)

            # ëŒ“ê¸€ ìˆ˜ì§‘
            comments = self.get_comments(video_id)

            # Rate Limiting
            time.sleep(self.api_call_delay)

            # ì±„ë„ ì •ë³´
            channel_info = self.get_channel_info(snippet['channelId'])

            return {
                'video_id': video_id,
                'keyword': keyword or '',
                'title': snippet.get('title', ''),
                'description': snippet.get('description', ''),
                'channel_title': snippet.get('channelTitle', ''),
                'published_at': snippet.get('publishedAt', ''),
                'view_count': int(statistics.get('viewCount', 0)),
                'like_count': int(statistics.get('likeCount', 0)),
                'comment_count': int(statistics.get('commentCount', 0)),
                'duration': video['contentDetails'].get('duration', ''),
                'tags': ', '.join(snippet.get('tags', [])),
                'category_id': snippet.get('categoryId', ''),
                'subscriber_count': channel_info.get('subscriber_count', 0) if channel_info else 0,
                'thumbnail_filename': thumbnail_filename or '',
                'transcript': transcript or '',
                'comments': comments
            }

        except Exception as e:
            self.logger.error(f"ë¹„ë””ì˜¤ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜ ({video_id}): {e}")
            return None

    def get_comments(self, video_id, max_comments=20):
        """ëŒ“ê¸€ ìˆ˜ì§‘"""
        comments = []
        try:
            response = self.youtube.commentThreads().list(
                part='snippet',
                videoId=video_id,
                maxResults=max_comments,
                order='relevance'
            ).execute()

            for item in response['items']:
                comment = item['snippet']['topLevelComment']['snippet']
                comments.append({
                    'author': comment['authorDisplayName'],
                    'text': comment['textDisplay'],
                    'like_count': comment['likeCount'],
                    'published_at': comment['publishedAt']
                })

        except Exception as e:
            self.logger.info(f"ëŒ“ê¸€ ìˆ˜ì§‘ ë¶ˆê°€ ({video_id}): {str(e)}")

        return comments

    def get_channel_info(self, channel_id):
        """ì±„ë„ ì •ë³´ ìˆ˜ì§‘"""
        try:
            response = self.youtube.channels().list(
                part='statistics',
                id=channel_id
            ).execute()

            if response['items']:
                stats = response['items'][0]['statistics']
                return {
                    'subscriber_count': int(stats.get('subscriberCount', 0))
                }
        except Exception as e:
            self.logger.error(f"ì±„ë„ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜ ({channel_id}): {e}")
        return None

    def load_urls_from_csv(self, csv_source):
        """CSV íŒŒì¼ ë˜ëŠ” URLì—ì„œ URL ëª©ë¡ ì½ê¸°"""
        try:
            # URLì¸ì§€ íŒŒì¼ ê²½ë¡œì¸ì§€ í™•ì¸
            if csv_source.startswith('http://') or csv_source.startswith('https://'):
                print(f"\nğŸŒ ì›¹ì—ì„œ CSV ë‹¤ìš´ë¡œë“œ ì¤‘...")
                df = pd.read_csv(csv_source, encoding='utf-8')
            else:
                print(f"\nğŸ“‚ ë¡œì»¬ CSV íŒŒì¼ ì½ëŠ” ì¤‘...")
                df = pd.read_csv(csv_source, encoding='utf-8')

            # CSV êµ¬ì¡° ë¶„ì„
            print(f"\nğŸ“Š CSV ë°ì´í„° ë¶„ì„:")
            print(f"   ì´ í–‰ ìˆ˜: {len(df)}")
            print(f"   ì»¬ëŸ¼: {list(df.columns)}")

            # URL ì¶”ì¶œ ë¡œì§
            urls_with_keywords = []

            # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ í‚¤ì›Œë“œë¼ê³  ê°€ì •
            keyword_col = df.columns[0]

            for idx, row in df.iterrows():
                keyword = row[keyword_col]
                # ê° í–‰ì˜ ëª¨ë“  ì…€ì„ ê²€ì‚¬í•˜ì—¬ YouTube URL ì°¾ê¸°
                for col in df.columns[1:]:
                    cell_value = str(row[col])
                    if 'youtube.com' in cell_value or 'youtu.be' in cell_value:
                        urls_with_keywords.append({
                            'url': cell_value.strip(),
                            'keyword': keyword
                        })

            print(f"   ì¶”ì¶œëœ URL: {len(urls_with_keywords)}ê°œ")
            return urls_with_keywords

        except Exception as e:
            print(f"âŒ CSV ì½ê¸° ì˜¤ë¥˜: {e}")
            self.logger.error(f"CSV ì½ê¸° ì˜¤ë¥˜: {e}")
            return []

    def collect_from_csv(self, csv_path):
        """CSV íŒŒì¼ì—ì„œ URL ëª©ë¡ì„ ì½ì–´ ë°°ì¹˜ ì²˜ë¦¬"""
        print("\n" + "="*60)
        print("ğŸ“Š CSV íŒŒì¼ì—ì„œ URL ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘")
        print("="*60)

        # CSV íŒŒì¼ ì½ê¸°
        urls_data = self.load_urls_from_csv(csv_path)

        if not urls_data:
            print("âŒ ì²˜ë¦¬í•  URLì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        total = len(urls_data)
        print(f"\nğŸ“‹ ì´ {total}ê°œì˜ URLì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

        # ì§„í–‰ ìƒí™© í‘œì‹œ
        for idx, data in enumerate(urls_data, 1):
            url = data['url']
            keyword = data['keyword']

            print(f"\n{'='*60}")
            print(f"ì§„í–‰: {idx}/{total} ({idx/total*100:.1f}%)")
            print(f"í‚¤ì›Œë“œ: {keyword}")
            print(f"URL: {url[:80]}...")

            video_id = self.extract_video_id(url)

            if not video_id:
                print("âŒ ì˜¬ë°”ë¥´ì§€ ì•Šì€ YouTube URL")
                self.failed_urls.append({'url': url, 'keyword': keyword, 'reason': 'Invalid URL'})
                self.logger.warning(f"ì˜ëª»ëœ URL: {url}")
                continue

            # ì¤‘ë³µ ì²´í¬
            if video_id in self.processed_ids:
                print(f"â­ï¸  ì´ë¯¸ ìˆ˜ì§‘ëœ ì˜ìƒ (ID: {video_id})")
                continue

            print(f"ğŸ” ì˜ìƒ ì •ë³´ ìˆ˜ì§‘ ì¤‘... (ID: {video_id})")

            video_info = self.get_video_info(video_id, keyword)

            if video_info:
                self.results.append(video_info)
                self.processed_ids.add(video_id)

                print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {video_info['title'][:50]}...")
                print(f"   ğŸ“Š ì¡°íšŒìˆ˜: {video_info['view_count']:,}")
                print(f"   ğŸ‘ ì¢‹ì•„ìš”: {video_info['like_count']:,}")
                print(f"   ğŸ’¬ ëŒ“ê¸€: {video_info['comment_count']:,}")
                print(f"   ğŸ“ ìë§‰: {'ìˆìŒ' if video_info['transcript'] else 'ì—†ìŒ'}")
                print(f"   ğŸ–¼ï¸  ì¸ë„¤ì¼: {'ì €ì¥ë¨' if video_info['thumbnail_filename'] else 'ì‹¤íŒ¨'}")

                self.logger.info(f"ìˆ˜ì§‘ ì™„ë£Œ: {video_id} - {video_info['title']}")
            else:
                print("âŒ ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.failed_urls.append({'url': url, 'keyword': keyword, 'reason': 'Failed to fetch'})
                self.logger.error(f"ìˆ˜ì§‘ ì‹¤íŒ¨: {url}")

            # 10ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
            if idx % 10 == 0:
                print("\nğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘...")
                self.save_progress()

        # ìµœì¢… ì €ì¥
        print("\nğŸ’¾ ìµœì¢… ì§„í–‰ ìƒí™© ì €ì¥ ì¤‘...")
        self.save_progress()

        # í†µê³„ ì¶œë ¥
        self.print_statistics()

    def print_statistics(self):
        """ìˆ˜ì§‘ í†µê³„ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“ˆ ìˆ˜ì§‘ í†µê³„")
        print("="*60)
        print(f"âœ… ì„±ê³µ: {len(self.results)}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {len(self.failed_urls)}ê°œ")

        if self.results:
            # í‚¤ì›Œë“œë³„ í†µê³„
            keywords = {}
            for item in self.results:
                kw = item.get('keyword', 'ë¯¸ë¶„ë¥˜')
                if kw not in keywords:
                    keywords[kw] = {'count': 0, 'total_views': 0}
                keywords[kw]['count'] += 1
                keywords[kw]['total_views'] += item['view_count']

            print(f"\nğŸ“Š í‚¤ì›Œë“œë³„ í†µê³„:")
            for kw, stats in keywords.items():
                avg_views = stats['total_views'] / stats['count']
                print(f"   {kw}: {stats['count']}ê°œ (í‰ê·  ì¡°íšŒìˆ˜: {avg_views:,.0f})")

        if self.failed_urls:
            print(f"\nâŒ ì‹¤íŒ¨í•œ URL:")
            for item in self.failed_urls[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                print(f"   {item['url'][:60]}... - {item['reason']}")
            if len(self.failed_urls) > 5:
                print(f"   ... ì™¸ {len(self.failed_urls) - 5}ê°œ")

    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        if not self.results:
            print("\nâŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\nğŸ’¾ {len(self.results)}ê°œ ì˜ìƒ ë°ì´í„° ì €ì¥ ì¤‘...")

        try:
            # ê¸°ë³¸ ì •ë³´ ë°ì´í„°í”„ë ˆì„
            basic_data = []
            for item in self.results:
                basic_data.append({
                    'ì˜ìƒ ID': item['video_id'],
                    'í‚¤ì›Œë“œ': item.get('keyword', ''),
                    'ì œëª©': item['title'],
                    'ì±„ë„ëª…': item['channel_title'],
                    'ì—…ë¡œë“œ ë‚ ì§œ': item['published_at'],
                    'ì¡°íšŒìˆ˜': item['view_count'],
                    'ì¢‹ì•„ìš” ìˆ˜': item['like_count'],
                    'ëŒ“ê¸€ ìˆ˜': item['comment_count'],
                    'êµ¬ë…ì ìˆ˜': item['subscriber_count'],
                    'íƒœê·¸': item['tags'],
                    'ì„¤ëª…': item['description'],
                    'ì¸ë„¤ì¼ íŒŒì¼ëª…': item.get('thumbnail_filename', '')
                })

            # ëŒ“ê¸€ ë°ì´í„°í”„ë ˆì„
            comment_data = []
            for item in self.results:
                for comment in item['comments']:
                    comment_data.append({
                        'ì˜ìƒ ID': item['video_id'],
                        'í‚¤ì›Œë“œ': item.get('keyword', ''),
                        'ì˜ìƒ ì œëª©': item['title'],
                        'ëŒ“ê¸€ ì‘ì„±ì': comment['author'],
                        'ëŒ“ê¸€ ë‚´ìš©': comment['text'],
                        'ëŒ“ê¸€ ì¢‹ì•„ìš”': comment['like_count'],
                        'ëŒ“ê¸€ ì‘ì„±ì¼': comment['published_at']
                    })

            # ìŠ¤í¬ë¦½íŠ¸ ë°ì´í„°í”„ë ˆì„
            script_data = []
            for item in self.results:
                if item.get('transcript'):
                    script_data.append({
                        'ì˜ìƒ ID': item['video_id'],
                        'í‚¤ì›Œë“œ': item.get('keyword', ''),
                        'ì˜ìƒ ì œëª©': item['title'],
                        'ìŠ¤í¬ë¦½íŠ¸': item['transcript']
                    })

            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"YouTube_Shorts_Data_{timestamp}.xlsx"

            # Excel íŒŒì¼ ì €ì¥
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                pd.DataFrame(basic_data).to_excel(writer, sheet_name='ì˜ìƒì •ë³´', index=False)
                if comment_data:
                    pd.DataFrame(comment_data).to_excel(writer, sheet_name='ëŒ“ê¸€ì •ë³´', index=False)
                if script_data:
                    pd.DataFrame(script_data).to_excel(writer, sheet_name='ìŠ¤í¬ë¦½íŠ¸', index=False)

            print(f"âœ… Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")

            # JSON íŒŒì¼ë„ ì €ì¥ (ë°±ì—…ìš©)
            json_filename = f"YouTube_Shorts_Data_{timestamp}.json"
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)

            print(f"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {json_filename}")

            # ì‹¤íŒ¨ ëª©ë¡ ì €ì¥
            if self.failed_urls:
                failed_filename = f"Failed_URLs_{timestamp}.json"
                with open(failed_filename, 'w', encoding='utf-8') as f:
                    json.dump(self.failed_urls, f, ensure_ascii=False, indent=2)
                print(f"âš ï¸  ì‹¤íŒ¨ URL ëª©ë¡ ì €ì¥: {failed_filename}")

            self.logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")

        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            self.logger.error(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¬ YouTube Shorts ë°ì´í„° ìˆ˜ì§‘ê¸° v2")
    print("=" * 60)
    print("ğŸ“ ìƒˆë¡œìš´ ê¸°ëŠ¥:")
    print("   â€¢ CSV íŒŒì¼ì—ì„œ URL ë°°ì¹˜ ì²˜ë¦¬")
    print("   â€¢ í‚¤ì›Œë“œ íƒœê¹…")
    print("   â€¢ ì¸ë„¤ì¼ ìë™ ë‹¤ìš´ë¡œë“œ")
    print("   â€¢ ìë§‰ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)")
    print("   â€¢ ì§„í–‰ ìƒí™© ìë™ ì €ì¥")
    print("   â€¢ Excel íŒŒì¼ë¡œ ìë™ ì €ì¥")
    print("=" * 60)

    collector = YouTubeShortsCollectorV2()

    # ì´ì „ ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸° ì„ íƒ
    if os.path.exists(collector.progress_file):
        choice = input("\nì´ì „ ì§„í–‰ ìƒí™©ì„ ë¶ˆëŸ¬ì˜¤ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if choice == 'y':
            collector.load_progress()

    # API í‚¤ ì„¤ì •
    collector.setup_api_key()

    # CSV íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URL ì…ë ¥
    print("\n" + "="*60)
    print("ğŸ“ CSV ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ")
    print("="*60)
    print("ğŸ’¡ CSV ì…ë ¥ ë°©ë²•:")
    print("   1. ë¡œì»¬ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: ./data.csv)")
    print("   2. êµ¬ê¸€ ì‹œíŠ¸ ì›¹ ë°œí–‰ URL (CSV í˜•ì‹)")
    print("\nğŸ’¡ CSV íŒŒì¼ í˜•ì‹:")
    print("   - ì²« ë²ˆì§¸ ì»¬ëŸ¼: í‚¤ì›Œë“œ")
    print("   - ë‚˜ë¨¸ì§€ ì»¬ëŸ¼: YouTube URL")
    print("\nğŸ’¡ êµ¬ê¸€ ì‹œíŠ¸ ì›¹ ë°œí–‰ ë°©ë²•:")
    print("   íŒŒì¼ > ê³µìœ  > ì›¹ì— ê²Œì‹œ > 'ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’(.csv)' ì„ íƒ")

    while True:
        csv_source = input("\nğŸ“‹ CSV íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()

        if not csv_source:
            print("âŒ ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        # URLì´ê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì§„í–‰
        if csv_source.startswith('http://') or csv_source.startswith('https://'):
            print("âœ… ì›¹ URLë¡œ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        elif os.path.exists(csv_source):
            print("âœ… ë¡œì»¬ íŒŒì¼ë¡œ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        else:
            print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì´ê±°ë‚˜ ì˜¬ë°”ë¥¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ë°ì´í„° ìˆ˜ì§‘
    collector.collect_from_csv(csv_source)

    # ê²°ê³¼ ì €ì¥
    collector.save_results()

    print("\nğŸ‰ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì™„ë£Œ!")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
    print(f"   - Excel íŒŒì¼")
    print(f"   - JSON íŒŒì¼")
    print(f"   - ì¸ë„¤ì¼: {collector.thumbnail_dir}/ í´ë”")
    print(f"   - ë¡œê·¸: youtube_collector.log")
    input("\nì¢…ë£Œí•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")


if __name__ == "__main__":
    main()